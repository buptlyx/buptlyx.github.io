<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>从0开始的大语言模型之路(1)</title>
    <url>/2025/12/01/llm1/</url>
    <content><![CDATA[<h3 id="故事背景"><a href="#故事背景" class="headerlink" title="故事背景"></a>故事背景</h3><hr>
<p>&emsp;&emsp;这学期，我们的神经网络课程设计大作业是一个经典的图像生成文字（ImageCaption）任务。直到今天，我才着手开始写代码，花了一些时间把数据集整理好，然后把任务需求统统塞给<strong>Gemini3Pro</strong>后，Gemini只花了不到半分钟的时间就生成了所有的代码，并且能完整运行不报错。虽然我深知现在的大语言模型在编程方面已经相当成熟，但是还是不由得感叹我们堂堂北邮人工智能专业里，最核心的专业课的课程大作业居然被AI给秒了？<br>&emsp;&emsp;虽然受限于笔记本的显卡性能，Gemini给我的代码让我从下午五点跑到了晚上八点，但是这激发了上神经网络只是混个考勤的我，对于语言模型的学习兴趣，我打算从最最基础的知识开始学起，同时遵循我的偶像之一<strong>理查德·费曼</strong>的学习方法，边学边把学到的东西用最通俗易懂的方式讲出来。于是便有了这一篇文章，甚至这整个博客网站都是为了写这篇文章而专门搭建的。</p>
<h3 id="问题引入"><a href="#问题引入" class="headerlink" title="问题引入"></a>问题引入</h3><p>&emsp;&emsp;在深入探讨语言模型的原理前，我们不妨先抛出一个问题：</p>
<blockquote>
<p>语言模型是如何处理我们输入的问题，并输出我们想要的回答的？</p>
</blockquote>
<h3 id="分词"><a href="#分词" class="headerlink" title="分词"></a>分词</h3><p>&emsp;&emsp;首先，对于我们输入的一段文字，例如是<strong>把大象装进冰箱里需要几步</strong>这一段话，语言模型先会把这一段话利用预先训练好的分词器，进行分词处理（Tokenizations），被切成[‘把’,’大象’,’装’,’进’,’冰箱’,’里’,’需要’,’几’,’步’] 。这一个个用逗号分开的字符串又被称为”<strong>Token</strong>“。而语言模型本身是无法直接读取自然语言的信息的，所以在这一步后，模型会按照设定好的词表（Vocabulary），把它们转换为整型数，例如[189,24,43,…,91]，这些整数没有任何含义，只是用于映射到某个词的索引（Index）。</p>
<h3 id="词嵌入"><a href="#词嵌入" class="headerlink" title="词嵌入"></a>词嵌入</h3><p>&emsp;&emsp;接着，这些Token，或者说转换后的整型数，会被赋予一个独一无二的“身份证”——<strong>词向量</strong>。在词向量中，蕴含着这个Token一切的语义信息，获得这个词向量的过程，就是<strong>词嵌入</strong>（Embedding）。例如，“大象”这个词在词表中对应编号是24，模型识别到24后，得到一个4096维词向量，每一个维度都代表着“大象”这个词不同的信息。<br>&emsp;&emsp;当然词向量，也是向量，那么不同的词向量理所应当就可以进行数值上的计算。一个很流行的说法是：“国王”-“男人”+“女人”&#x3D;“皇后”。虽然这被许多人验证指出这并不是一个严谨的说法，但是我们可以管中窥豹，以此来理解词向量的用途。在3Blue1Brown的视频中对此给出了一个解释，皇后（Queen）的含义并不仅限于“女性的国王”这一层语义，可能还表示皇后乐队、善于社交的人等不同的语义。关于词向量，内容非常丰富且有趣，我还会出更多文章来深入阐释这一概念。</p>
<h3 id="注意力机制"><a href="#注意力机制" class="headerlink" title="注意力机制"></a>注意力机制</h3><p>&emsp;&emsp;当然，在一些词语的常见语义和在句子中的语义是有些差别的。还是举皇后的例子，单独一个词“皇后”，那么它的语义可能80%是“女性的国王”这一层。但是如果把“皇后”放到“乐队”前面，那么这个“皇后”的语义就变成了乐队的名称。在自然语言沟通中，这个道理是会被人类大脑普遍接受。那么，为了让模型更好地模拟这一过程，我们引入了一个强大的工具——<strong>注意力机制</strong>（Attention）。在自然语言处理领域最有建设性、最有代表性、最出圈的一篇论文《Attention is all you need》中，对注意力机制有更完整的阐述。后续我也将写更多的文章来单独讲解注意力机制。现在我们不需要理解注意力机制有什么深奥的数学原理，只需要懂运用注意力机制可以让词语在上下文中有更准确的含义就行。同时补充一下，我们还需要一个<strong>位置编码</strong>（Positional encoding）来让模型知道句子中词语出现的顺序。</p>
<h3 id="Transformer架构"><a href="#Transformer架构" class="headerlink" title="Transformer架构"></a>Transformer架构</h3><p>&emsp;&emsp;然后，一个很自然的想法就出现了：<strong>我明白了模型如何处理我的输入，那么语言模型是如何输出的呢？</strong> 这个问题其实才是理解语言模型原理的关键，而这个问题的答案也很简单，就是两个字“<strong>接龙</strong>”，语言模型做的工作，不过就是接收到你传入的句子，经过分词、词嵌入、注意力，再经过一层层神经网络的计算，得到你的句子下一个词的出现的概率，然后根据概率，选择策略（例如是输出最大概率或者输出概率最高的三个词中的一个）进行输出。最后将生成的词与原先的输入拼接在一起再重新输入到模型中，计算概率得到新的词，循环往复，直到出现<strong>结束符</strong>为止。这就是大名鼎鼎的<strong>Transformer</strong>架构。</p>
<h3 id="最开始的例子"><a href="#最开始的例子" class="headerlink" title="最开始的例子"></a>最开始的例子</h3><p>&emsp;&emsp;还是最开始的例子，往模型中输入：<strong>把大象装进冰箱里需要几步</strong>。实际上模型并不只是得到了这一段输入，正如前文所说，模型会做的只有“接龙”，如果只得到这一段输入，模型会从“步”字开始继续写故事。例如：</p>
<blockquote>
<p><strong>提问</strong>：把大象装进冰箱里需要几步<br><strong>回答</strong>：呢？这个问题是一个值得思考的问题。…</p>
</blockquote>
<p>&emsp;&emsp;答非所问，甚至并没有回答问题，反而回过头来问我们问题。为了达到问答的效果，各个AI平台都设计了独特的<strong>Prompt</strong>来让模型可以问答。所谓Prompt，类似平台在我们的输入句子前加上“<strong>用户说：</strong>”，结尾加上“<strong>AI回答：</strong>”，这样我们的输入实际上就是：</p>
<blockquote>
<p>用户说：把大象装进冰箱里需要几步 AI回答：</p>
</blockquote>
<p>&emsp;&emsp;再把这一段句子输入到模型中时，我们会惊奇的发现模型居然真的开始回答问题了！输入后，模型计算得到一个概率表，其中“要”这个词的概率最大，于是输出“要”。接着把“<strong>用户说：把大象装进冰箱里需要几步 AI回答：要</strong>”再输入到模型中，得到“<strong>用户说：把大象装进冰箱里需要几步 AI回答：要把</strong>”，由此循环往复，直到输出结束符后停止。Gemini3Pro得到的回答是：</p>
<blockquote>
<p>要把大象装进冰箱，总共分三步：</p>
<ol>
<li>把冰箱门打开。</li>
<li>把大象装进去。</li>
<li>把冰箱门带上。</li>
</ol>
</blockquote>
<hr>
<h3 id="简单聊聊"><a href="#简单聊聊" class="headerlink" title="简单聊聊"></a>简单聊聊</h3><p>&emsp;&emsp;以上是我目前对于语言模型一些能立马说出来的认识，当然这篇文章只是一个开篇综述，没有任何的代码或者数学推导，不过没有关系，我想要写的就是大部分人能看得懂的、入门级的<strong>偏教学类</strong>文章。后续也希望我可以继续更新，深入学习。</p>
]]></content>
      <tags>
        <tag>大模型,深度学习,Attention</tag>
      </tags>
  </entry>
</search>
